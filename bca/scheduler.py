#!/usr/bin/env python3
#
# scheduler.py - scheduler for training tasks
#
# SPDX-FileCopyrightText: Copyright (C) 2022-2023 Frank C Langbein <frank@langbein.org>, Cardiff University
# SPDX-License-Identifier: AGPL-3.0-or-later

from .cfg import Cfg

import os
import shutil
import glob
import subprocess
import time
import multiprocessing

class SlurmScheduler:
  """Provides run and check method to schedule and check completion of task on a slurm cluster.
  It assumes `rsync`, `ssh`, etc. are available on local and remote system.
  """

  def __init__(self, config, local_folder, id="bca", scw=True):
    """Setup scheduler.

    Args:
      * `config`: Configuration values, taken from `bca.cfg` using the json config files. See 
        arguments needed there (val variable in `bca.cfg.Cfg`);
      * `local_folder`: Local root folder containing the bca repository;
      * `id`: id to use for SCW jobs (extended by the task folder name)
      * `scw`: use work-around for SCW cluster to force fixed batch-size to avoid crash. See
         HACK comments in source.
    """
    # Setup config
    self.max_tasks = config["max_tasks"]
    self.host = config["host"]
    self.user = config["user"]
    self.account = config["account"]
    self.remote_folder = config["remote_folder"]
    self.partitions = config["partitions"]
    self.nodes = config["nodes"]
    self.ntasks = config["ntasks"]
    self.ntasks_per_node = config["ntasks_per_node"]
    self.cpus_per_task = config["cpus_per_task"]
    self.mem = config["mem"]
    self.gres = config["gres"]
    self.time = config["time"]
    self.modules = config["modules"]
    self.local_folder = local_folder
    self.id = id
    self.scw = scw # See HACK below to fix crash on specific hardware

  @staticmethod
  def _proc_res(res, out_start=0):
    # Helper to process output
    for line in res.stdout.decode("utf-8").split("\n")[out_start:]:
      for lline in reversed(line.split("\r")):
        if len(lline) > 0:
          line = lline
          break
      if len(line) > 0:
        print("    "+line)
    for line in res.stderr.decode("utf-8").split("\n"):
      for lline in reversed(line.split("\r")):
        if len(lline) > 0:
          line = lline
          break
      if len(line) > 0:
        print("    E:"+line)
    return res.returncode != 0

  def run(self, task):
    """Setup and schedule task.

    This synchronises the code and data and initiates the remote job. It stores information about
    the job locally, so it can find it again, in the model folder. That means if the scheduler
    is interrupted, it can pick it up from the interruption and check where the job is at.

    Args:
      * `task`: `task.py` file generated by `bca.train.Trainer` to execute the training task
    """
    print("  ## Sync'ing files")
    for src in ["bca", "requirements.txt", "cfg.json"]:
      res = subprocess.run(["rsync","-am","--delete",
                            "--exclude=__pycache__",
                            os.path.join(Cfg.val["path_root"],src),
                            self.user+"@"+self.host+":"+self.remote_folder],
                           capture_output=True)
      if SlurmScheduler._proc_res(res):
        raise RuntimeError(f"Sync'ing {src} failed")

    task_path = os.path.dirname(task)
    data_path = os.path.dirname(os.path.dirname(os.path.dirname(task_path)))
    res = subprocess.run(["ssh",self.user+"@"+self.host,"mkdir -p "+os.path.join(self.remote_folder,data_path)],capture_output=True)
    if SlurmScheduler._proc_res(res):
      raise RuntimeError(f"Mkdir {data_path} failed")
    res = subprocess.run(["rsync","-am","--delete",
                          "--include=*.npy","--exclude=*",
                          os.path.join(self.local_folder,data_path)+"/",
                          self.user+"@"+self.host+":"+os.path.join(self.remote_folder,data_path)],
                         capture_output=True)
    if SlurmScheduler._proc_res(res):
      raise RuntimeError(f"Sync'ing {data_path} failed")

    print(f"  ## Schedule job for {task}")
    with open(os.path.join(self.local_folder,task_path,"job.sh"), "w") as f:
      f.write( "#!/bin/sh -l\n")
      f.write(f"#SBATCH --job-name={self.id}/{task_path}\n")
      f.write(f"#SBATCH --output={self.remote_folder}/{task_path}/out.log\n")
      f.write(f"#SBATCH --error={self.remote_folder}/{task_path}/err.log\n")
      f.write(f"#SBATCH -p {self.partitions}\n")
      f.write(f"#SBATCH --nodes={self.nodes}\n")
      f.write(f"#SBATCH --ntasks={self.ntasks}\n")
      f.write(f"#SBATCH --ntasks-per-node={self.ntasks_per_node}\n")
      f.write(f"#SBATCH --cpus-per-task={self.cpus_per_task}\n")
      f.write(f"#SBATCH --mem={self.mem}\n")
      f.write(f"#SBATCH --gres={self.gres}\n")
      f.write(f"#SBATCH --time={self.time}\n")
      if len(self.modules) > 0:
        f.write("\nmodule purge\n")
        for m in self.modules:
          f.write(f"module load {m}\n")
      f.write( "\n")
      # HACK: this fixes an issue with non-constant batch sizes on SCW V100-16GB hardware with CUDA 11.5; cudnn 8.{3,6} (not tested elsewhere).abs(x)
      if self.scw:
        f.write('export BCA_DEV=FIXED_BATCH_SIZE\n\n')
      # END HACK
      f.write(f"cd ~/{self.remote_folder}\n")
      f.write(f'echo "Job: $SLURM_JOB_NAME - $SLURM_JOB_ID on $SLURM_JOB_NODELIST"\n')
      f.write(f"/usr/bin/env python3 {task}\n")
      f.write(f'test "$?" = 0 && date >~/{self.remote_folder}/{task_path}/done\n')
    res = subprocess.run(["ssh",self.user+"@"+self.host,"mkdir -p "+os.path.join(self.remote_folder,task_path)],capture_output=True)
    if SlurmScheduler._proc_res(res):
      raise RuntimeError(f"Mkdir {task_path} failed")
    res = subprocess.run(["rsync","-am","--delete",
                          "--exclude=__pycache__",
                          os.path.join(self.local_folder,task_path)+"/",
                          self.user+"@"+self.host+":"+os.path.join(self.remote_folder,task_path)],
                         capture_output=True)
    if SlurmScheduler._proc_res(res):
      raise RuntimeError(f"Sync'ing {task_path} failed")

    res = subprocess.run(["ssh",self.user+"@"+self.host,f"sbatch -A {self.account} {self.remote_folder}/{task_path}/job.sh"],
                         capture_output=True)
    if SlurmScheduler._proc_res(res):
      raise RuntimeError(f"Scheduling {task} failed")

  def check(self, task):
    """Check status of the task.

    Checks the status of the task and returns it for processing by "bca.scheduler.schedule()".

    Args:
      * `task`: `task.py` file generated by `bca.train.Trainer` to execute the training task
    """
    task_path = os.path.dirname(task)
    res = subprocess.run(["ssh",self.user+"@"+self.host,f"ls {self.remote_folder}/{task_path} 2>/dev/null 1>&2"], capture_output=True)
    if SlurmScheduler._proc_res(res):
      return "OFFLINE"
    result = "DONE"
    res = subprocess.run(["ssh",self.user+"@"+self.host,f"ls {self.remote_folder}/{task_path}/done 2>/dev/null 1>&2"], capture_output=True)
    if SlurmScheduler._proc_res(res):
      res = subprocess.run(["ssh",self.user+"@"+self.host,f"squeue -n {self.id}/{task_path}"], capture_output=True)
      SlurmScheduler._proc_res(res, out_start=1)
      output = res.stdout.decode("utf-8").split("\n")[:-1]
      if len(output) > 1: # Need at least two lines of output to have the process still running
        res = subprocess.run(["ssh",self.user+"@"+self.host,f"tail -4 {self.remote_folder}/{task_path}/out.log 2>/dev/null"], capture_output=True)
        SlurmScheduler._proc_res(res)
        return "WAIT"
      result = "FAILED"
    res = subprocess.run(["rsync","-am","--delete",
                          "--exclude=__pycache__",
                          self.user+"@"+self.host+":"+os.path.join(self.remote_folder,task_path)+"/",
                          task_path],
                         capture_output=True)
    if SlurmScheduler._proc_res(res):
      raise RuntimeError(f"Copying {task} results failed")
    res = subprocess.run(["ssh",self.user+"@"+self.host,f"rm -rf {self.remote_folder}/{task_path}"], capture_output=True)
    if SlurmScheduler._proc_res(res):
      raise RuntimeError(f"Removing remote result folder failed")
    return result

class HostScheduler:
  """Provides run and check method to schedule and check completion of task on a single host (assumed to be able to handle one task at a time).
  It assumes rsync, ssh, etc. are available on local and remote system.
  """

  def __init__(self, config, local_folder):
    """Setup scheduler.

    Args:
      * `config`: Configuration values, taken from `bca.cfg` using the json config files. See 
        arguments needed there (val variable in `bca.cfg.Cfg`);
      * `local_folder`: Local root folder containing the bca repository;
      * `id`: id to use for jobs (extended by the task folder name)
    """
    # Config
    self.max_tasks = 1
    self.host = config["host"]
    self.user = config["user"]
    self.remote_folder = config["remote_folder"]
    self.local_folder = local_folder

  @staticmethod
  def _proc_res(res, out_start=0):
    # Helper to process output
    for line in res.stdout.decode("utf-8").split("\n")[out_start:]:
      for lline in reversed(line.split("\r")):
        if len(lline) > 0:
          line = lline
          break
      if len(line) > 0:
        print("    "+line)
    for line in res.stderr.decode("utf-8").split("\n"):
      for lline in reversed(line.split("\r")):
        if len(lline) > 0:
          line = lline
          break
      if len(line) > 0:
        print("    E:"+line)
    return res.returncode != 0

  def run(self, task):
    """Setup and schedule task.

    This synchronises the code and data and initiates the remote job. It stores information about
    the job locally, so it can find it again, in the model folder. That means if the scheduler
    is interrupted, it can pick it up from the interruption and check where the job is at.

    Args:
      * `task`: `task.py` file generated by `bca.train.Trainer` to execute the training task
    """
    print("  ## Sync'ing files")
    for src in ["bca", "requirements.txt", "cfg.json"]:
      res = subprocess.run(["rsync","-am","--delete",
                            "--exclude=__pycache__",
                            os.path.join(Cfg.val["path_root"],src),
                            self.user+"@"+self.host+":"+self.remote_folder],
                           capture_output=True)
      if HostScheduler._proc_res(res):
        raise RuntimeError(f"Sync'ing {src} failed")

    task_path = os.path.dirname(task)
    data_path = os.path.dirname(os.path.dirname(os.path.dirname(task_path)))
    res = subprocess.run(["ssh",self.user+"@"+self.host,f"mkdir -p {os.path.join(self.remote_folder,data_path)}"],capture_output=True)
    if HostScheduler._proc_res(res):
      raise RuntimeError(f"Mkdir {data_path} failed")
    res = subprocess.run(["rsync","-am","--delete",
                          "--include=*.npy","--exclude=*",
                          os.path.join(self.local_folder,data_path)+"/",
                          self.user+"@"+self.host+":"+os.path.join(self.remote_folder,data_path)],
                         capture_output=True)
    if HostScheduler._proc_res(res):
      raise RuntimeError(f"Sync'ing {data_path} failed")

    print(f"  ## Schedule job for {task}")
    with open(os.path.join(self.local_folder,task_path,"job.sh"), "w") as f:
      f.write( "#!/bin/sh -l\n")
      f.write(f'cd ~/{self.remote_folder}\n')
      f.write(f'echo -n $$ >{task_path}/pid\n')
      f.write(f'/usr/bin/env python3 {task} >{task_path}/out.log 2>{task_path}/err.log\n')
      f.write(f'test "$?" = 0 && date >~/{self.remote_folder}/{task_path}/done\n')
    res = subprocess.run(["ssh",self.user+"@"+self.host,f"mkdir -p {os.path.join(self.remote_folder,task_path)}"],capture_output=True)
    if HostScheduler._proc_res(res):
      raise RuntimeError(f"Mkdir {task_path} failed")
    res = subprocess.run(["rsync","-am","--delete",
                          "--exclude=__pycache__",
                          os.path.join(self.local_folder,task_path)+"/",
                          self.user+"@"+self.host+":"+os.path.join(self.remote_folder,task_path)],
                         capture_output=True)
    if HostScheduler._proc_res(res):
      raise RuntimeError(f"Sync'ing {task_path} failed")

    res = subprocess.run(["ssh",self.user+"@"+self.host,f"nohup sh {self.remote_folder}/{task_path}/job.sh >/dev/null 2>&1 &"],
                         capture_output=True)
    if HostScheduler._proc_res(res):
      raise RuntimeError(f"Scheduling {task} failed")

  def check(self, task):
    """Check status of the task.

    Checks the status of the task and returns it for processing by "bca.scheduler.schedule()".

    Args:
      * `task`: `task.py` file generated by `bca.train.Trainer` to execute the training task
    """
    task_path = os.path.dirname(task)
    res = subprocess.run(["ssh",self.user+"@"+self.host,f"ls {self.remote_folder}/{task_path} 2>/dev/null 1>&2"], capture_output=True)
    if HostScheduler._proc_res(res):
      return "OFFLINE"
    result = "DONE"
    res = subprocess.run(["ssh",self.user+"@"+self.host,f"ls {self.remote_folder}/{task_path}/done 2>/dev/null 1>&2"], capture_output=True)
    if HostScheduler._proc_res(res):
      res = subprocess.run(["ssh",self.user+"@"+self.host,f"test -f {self.remote_folder}/{task_path}/pid && ps -p `cat {self.remote_folder}/{task_path}/pid`"], capture_output=True)
      HostScheduler._proc_res(res, out_start=1)
      output = res.stdout.decode("utf-8").split("\n")[:-1]
      if len(output) > 1: # Need at least two lines of output to have the process still running
        res = subprocess.run(["ssh",self.user+"@"+self.host,f"tail -4 {self.remote_folder}/{task_path}/out.log 2>/dev/null"], capture_output=True)
        HostScheduler._proc_res(res)
        return "WAIT"
      result = "FAILED"
    res = subprocess.run(["rsync","-am","--delete",
                          "--exclude=__pycache__",
                          self.user+"@"+self.host+":"+os.path.join(self.remote_folder,task_path)+"/",
                          task_path],
                         capture_output=True)
    if HostScheduler._proc_res(res):
      raise RuntimeError(f"Copying {task} results failed")
    res = subprocess.run(["ssh",self.user+"@"+self.host,f"rm -rf {self.remote_folder}/{task_path}"], capture_output=True)
    if HostScheduler._proc_res(res):
      raise RuntimeError("Removing remote result folder failed")
    return result

class LocalScheduler:
  """Provides run and check method to schedule and check completion of task locally (assumed to be able to handle one task at a time).
  """

  def __init__(self):
    """Setup scheduler.
    """
    # Config
    self.max_tasks = 1
    self.process = None

  def _execute(self, task):
    # Helper to execute task locally in separate process
    from contextlib import redirect_stdout, redirect_stderr
    task_path = os.path.dirname(task)
    with open(os.path.join(task_path,"err.log"), "a" if os.path.isfile(os.path.join(task_path,"err.log")) else "w") as ferr:
      with open(os.path.join(task_path,"out.log"), "a" if os.path.isfile(os.path.join(task_path,"out.log")) else "w") as fout:
        with redirect_stderr(ferr):
          with redirect_stdout(fout):
            with open(task) as f:
              exec(compile(f.read(), task, "exec"))

  def run(self, task):
    """Setup and schedule task.

    This simply runs the job locally in a separate process, using the data stored locally directly.
    If the scheduler is interrupted this local job will also be interrupted (but can be continued from
    the last save model for the task).

    Args:
      * `task`: `task.py` file generated by `bca.train.Trainer` to execute the training task
    """
    if Cfg.val["multiprocessing"]:
      self.process = multiprocessing.Process(target=self._execute,kwargs={"task": task})
      self.process.start()
    else:
      self._execute(task)

  def check(self, task):
    """Check status of the task.

    Checks the status of the task and returns it for processing by "bca.scheduler.schedule()".

    Args:
      * `task`: `task.py` file generated by `bca.train.Trainer` to execute the training task
    """
    task_path = os.path.dirname(task)
    if Cfg.val["multipropcessing"]:
      if self.process is None:
        if os.path.isfile(os.path.join(task_path,"status")):
          with open(os.path.join(task_path,"status"), "r") as f:
            status = f.read()
          if len(status) >= 8 and status[0:8] == "training":
            if os.path.exists(os.path.join(task_path,"last")):
              return "DONE"
          os.remove(os.path.join(task_path,"status"))
        return "OFFLINE"
      if self.process.is_alive():
        with open(os.path.join(task_path,"out.log"),"r") as f:
          for line in (f.readlines()[-4:]):
            print("  "+line.strip(),)
        return "WAIT"
      if os.path.isdir(os.path.join(task_path,"last")):
        return "DONE"
      return "FAILED"
    if os.path.isfile(os.path.join(task_path,"status")):
      with open(os.path.join(task_path,"status"), "r") as f:
        status = f.read()
      if len(status) >= 8 and status[0:8] == "training":
        if os.path.exists(os.path.join(task_path,"last")):
          return "DONE"
      os.remove(os.path.join(task_path,"status"))
    return "FAILED"

def schedule(task_folder="results", wait=60, notebook=True):
  """Run scheduler.

  This checks the `task_folder` for any `task.py` jobs to execute and runs these on the
  executors which are specified in the configuration (see `bca.cfg.Cfg`). Depending on
  how many jobs can be started on the executor, it checks if a new job can be started.
  It also checks the status of existing jobs and updates information accordingly. It
  uses the various schedulers to execute them on different remote (or local) platforms.
  It can be interrupted and restarted (but a job run by the local scheduler will be
  interrupted). It stops when all jobs are completed (or when it is interrupted). There
  should only be one scheduler running for a task folder.

  Note, `bca/scheduler.py` can also be run from the command line to execute the scheduler.

  The scheduler is likely only to work on Linux or UNIX-like systems and requires `ssh`
  and `rsync` to run, among other standard UNIX tools. Under other operating systems,
  it may be best to run it in a VM (e.g. running a notebook/lab server to execute this
  from via a browser).
  
  To run this from the command line write a script such as
  ```python
  if __name__ == '__main__':
    from bca.bca.scheduler import schedule, schedule_clean
    task_folder="results"
    schedule_clean(task_folder=task_folder)
    schedule(task_folder=task_folder, wait=60, notebook=False)
  ```

  Args:
    * `task_folder`: Root of folder hierarchy containing tasks;
    * `wait`: seconds to wait between checks/scheduling new jobs;
    * `notebook`: format output for notebook (only shows latest results for clarify).
  """
  if notebook:
    from IPython import display

  # Sanity checks
  if not os.name == 'posix':                                                                         
    print("**WARNING - ths scheduler only runs reliably and is only supported on Linux/POSIX**")  
  local_folder = os.path.dirname(os.path.abspath(task_folder))
  if not os.path.isdir(local_folder): 
    raise RuntimeError("Cannot find location of data-root folder (containing {local_folder})")
 
  # Collect executors from config
  execs = {}
  for k in Cfg.val["executors"].keys():
    t = Cfg.val["executors"][k]["type"]
    if t == "slurm":
      execs[k] = SlurmScheduler(Cfg.val["executors"][k], local_folder, scw=True if k == "scw" else False) # See scw HACK above.
    elif t == "local":
      execs[k] = LocalScheduler()
    elif t == "host":
      execs[k] = HostScheduler(Cfg.val["executors"][k], local_folder)
    else:
      raise RuntimeError(f"Unknown executor type {t}")
  first_run = True

  # Keep scheduling (until nothing more found; can be interrupted)
  while True:
    if not notebook:
      print("========================================================================")
    not_scheduled = 0
    running_total = 0
    running = {}
    for k in execs.keys():
      running[k] = 0
    # Check running
    tasks = glob.glob(os.path.join(task_folder,"**","task.py"), recursive=True)
    for task in tasks:
      task_path = os.path.dirname(task)
      if os.path.isfile(os.path.join(task_path,"status")):
        with open(os.path.join(task_path,"status"), "r") as f:
          status = f.read()
        if len(status) >= 8 and status[0:8] == "training":
          print(f"# Status {task_path}:")
          key = status.split(":")[1].strip()
          stat = execs[key].check(task)
          print(f"  {stat}")
          if stat == "DONE" or stat == "FAILED":
            with open(os.path.join(task_path,"status"), "w") as f:
              f.write("end")
          else:
            running[k] += 1
            running_total += 1
    # Schedule
    tasks = glob.glob(os.path.join(task_folder,"**","task.py"), recursive=True)
    for task in tasks:
      task_path = os.path.dirname(task)
      if not os.path.isfile(os.path.join(task_path,"status")):
        scheduled = False
        for k in execs.keys():
          if k not in Cfg.val["disabled_executors"]: # Only disable executors for new jobs
            if running[k] < execs[k].max_tasks:
              with open(os.path.join(task_path,"status"), "w") as f:
                f.write(f"training:{k}")
              print(f"# New {task_path}")
              try:
                execs[k].run(task)
              except Exception as e:
                print(e)
                if os.path.isdir(os.path.join(task_path,"last")):
                  shutil.rmtree(os.path.join(task_path,"last"))
                with open(os.path.join(task_path,"status"), "w") as f:
                  f.write(f"end")
              running[k] += 1
              running_total += 1
              scheduled = True
              break
        if scheduled == False:
          not_scheduled += 1
    if notebook:
      display.clear_output(wait=True)
    # Wait...
    if first_run:
      first_run = False # Makes sure local processes get initialised faster, if it has to be restarted
    else:
      if running_total == 0 and not_scheduled == 0:
        print("All tasks complete.")
        return
      time.sleep(wait)

def schedule_clean(task_folder="results"):
  """Cleanup failed tasks.

  Cleanup tasks that are failed to enable scheduling them again (assuming the issues have been fixed).

  Note, it also cleans up tasks that are not running and not complete.

  Args:
    * `task_folder`: Root of folder hierarchy containing tasks;
  """

  # Sanity checks
  if not os.name == 'posix':                                                                         
    print("**WARNING - ths scheduler only runs reliably and is only supported on Linux/POSIX**")  
  local_folder = os.path.dirname(os.path.abspath(task_folder))
  if not os.path.isdir(local_folder): 
    raise RuntimeError(f"Cannot find location of data-root folder (containing {local_folder})")
 
  # Keep scheduling (until nothing more found; can be interrupted)
  for task in glob.glob(task_folder+"/**/task.py", recursive=True):
    folder = os.path.dirname(task)
    if not os.path.exists(os.path.join(folder, "last")):
      clean=False
      if os.path.isfile(os.path.join(folder,"status")):
        with open(os.path.join(folder,"status"), "r") as f:
          status = f.read()
        if status[0:8] != "training":
          clean = True
        else:
          print(f"Running:  {folder}")
      else:
        clean=True
      if clean:
        disp=True
        for f in ["done", "err.log", "out.log", "status", "job.sh"]:
          p = os.path.join(folder, f)
          if os.path.exists(p):
            if disp:
              print(f"Cleaning: {folder}")
              disp = False
            os.remove(p)
